{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30280444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[375, 819, 358, 742, 337]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "rdd = sc.parallelize(range(1000))\n",
    "rdd.takeSample(False, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cab8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from operator import add\n",
    "sc.stop()\n",
    "#sc.SparkContext(appName=\"task2\")\n",
    "sc = pyspark.SparkContext(master='local[*]',appName='task2')\n",
    "f = sc.textFile(\"file01_Hd_Sp_Freq\")\n",
    "\n",
    "wc = f.flatMap(lambda line : line.split(' ')).map(lambda word : (word,1) ).reduceByKey(add)\n",
    "wc.saveAsTextFile(\"wc_out.txt\")\n",
    "f2 = sc.textFile(\"wc_out.txt\")\n",
    "f2.take(500)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a7f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 9), ('Hadoop', 6), ('Spark', 5)]\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "from pyspark import SparkContext\n",
    "from operator import add\n",
    "#sc = SparkContext(appName=\"Word_Freq\")\n",
    "sc = pyspark.SparkContext(master='local[*]',appName='Word_Freq')\n",
    "lines = sc.textFile(\"file01_Hd_Sp_Freq\") # counts is an RDD of the form (word, count)\n",
    "#counts = lines.flatMap(blah blah blah).reduceByKey(add)\n",
    "counts = lines.flatMap(lambda L: L.split(\" \")).map(lambda word: (word, 1)).reduceByKey(add)\\\n",
    ".sortBy(lambda L:L[1], ascending = False).take(3)\n",
    "# collect brings it to a list in local memory and you can extract info in the form of (word, count)\n",
    "print(counts)\n",
    "#output = counts.collect()\n",
    "sc.stop() # stop the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0efa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.140392\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "import random\n",
    "def inside(p):\n",
    "    x, y = random.random(), random.random()\n",
    "    return x*x + y*y < 1\n",
    "sc = pyspark.SparkContext(master='local[*]',appName='PI_Estimation')\n",
    "NUM_SAMPLES = 1000000\n",
    "count = sc.parallelize(range(0, NUM_SAMPLES)) \\\n",
    "             .filter(inside).count()\n",
    "print(\"Pi is roughly %f\" % (4.0 * count / NUM_SAMPLES))\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8622cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your own code, transform the code below: val lines = sc.textFile(\"file01_Hd_Sp_Freq.txt \") // transformed RDDs\n",
    "sc.stop()\n",
    "sc = pyspark.SparkContext(master='local[*]',appName='Word Count for I')\n",
    "lines = sc.textFile(\"file01_Hd_Sp_Freq\")\n",
    "#print(lines.collect())\n",
    "#lines = sc.textFile(\"test.txt\")\n",
    "#selfish = lines.filter(_[0] == \"I\")\n",
    "selfish = lines.filter(lambda x: x[0] == \"I\")\n",
    "messages = selfish.map(lambda line : line.split(\"\\t\")).map(lambda line : line[1])\n",
    "messages = selfish;\n",
    "messages.cache()\n",
    "messages.filter(lambda x: x.find(\"Spark\") != -1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172104c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
